{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnaF9DbMum8A",
        "outputId": "57f2f394-c6fa-4262-f30a-3dd9d1888bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQxW1vWv36I9",
        "outputId": "509599ff-710b-480e-9ddf-cc38f5be6630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16425 sha256=aee5aeae2c02487d77c22a98b0a198e45017084d89ad22aebc9c8ba0721f3406\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision efficientnet_pytorch matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy5bcWPA37HE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import os\n",
        "import warnings as w\n",
        "w.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjpAI9zha7Lu",
        "outputId": "c39e3270-9a31-48f4-b63a-a9597e96977c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVi5bTRM4A0_"
      },
      "outputs": [],
      "source": [
        "# Image transformations for augmentation, especially for classes with fewer samples\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-ZWLsqO4-js"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(\"/content/drive/MyDrive/Food Classification dataset/\", transform=train_transforms)\n",
        "\n",
        "# Split the dataset into training and testing sets (e.g., 80% train, 20% test)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Apply test transforms to the test dataset\n",
        "test_data.dataset.transform = test_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FErGermK5WZL",
        "outputId": "0d56acf4-5d1a-4f2e-c0b9-e1d9c92b0803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts in training data: Counter({7: 815, 2: 812, 8: 797, 27: 796, 21: 788, 13: 782, 9: 306, 17: 279, 5: 278, 12: 273, 6: 270, 3: 256, 24: 250, 14: 250, 4: 244, 20: 244, 10: 234, 15: 234, 25: 227, 16: 221, 23: 215, 19: 214, 11: 202, 26: 187, 18: 175, 1: 148, 22: 120, 0: 43})\n"
          ]
        }
      ],
      "source": [
        "train_labels = [dataset.targets[i] for i in train_data.indices]\n",
        "class_counts = Counter(train_labels)\n",
        "print(\"Class counts in training data:\", class_counts)\n",
        "\n",
        "# Oversampling or data augmentation strategy based on class imbalance\n",
        "class_weights = 1. / np.array([class_counts[i] for i in range(len(class_counts))])\n",
        "sample_weights = [class_weights[label] for label in train_labels]\n",
        "\n",
        "# Weighted sampler for handling imbalanced classes\n",
        "weighted_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdjOmUy35ZV7"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, sampler=weighted_sampler)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atR3GtvW5bWS",
        "outputId": "543fc5f0-c273-4b77-f49a-ac090db0f956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n",
            "100%|██████████| 20.4M/20.4M [00:00<00:00, 384MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        }
      ],
      "source": [
        "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "\n",
        "# Modify the final layer to match the number of food classes\n",
        "num_classes = 28\n",
        "model._fc = nn.Linear(model._fc.in_features, num_classes)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyX3DXgh5fES"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKHpLEdG5iMo"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, test_loader, num_epochs=10):\n",
        "    train_loss_history = []\n",
        "    test_loss_history = []\n",
        "    train_acc_history = []\n",
        "    test_acc_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss_history.append(running_loss / len(train_loader))\n",
        "        train_acc_history.append(100 * correct / total)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_loss_history.append(val_loss / len(test_loader))\n",
        "        test_acc_history.append(100 * val_correct / val_total)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "              f'Train Loss: {running_loss/len(train_loader):.4f}, '\n",
        "              f'Train Acc: {100 * correct / total:.2f}%, '\n",
        "              f'Val Loss: {val_loss/len(test_loader):.4f}, '\n",
        "              f'Val Acc: {100 * val_correct / val_total:.2f}%')\n",
        "\n",
        "    return train_loss_history, test_loss_history, train_acc_history, test_acc_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDQFUyQJ5kFL"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "train_loss, test_loss, train_acc, test_acc = train_model(model, criterion, optimizer, train_loader, test_loader, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "SSIVzRbS5nhQ",
        "outputId": "4f861dc3-f2e9-4fd6-89fc-7a0f3a960285"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loss' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d54aa0e8017f>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Cell 11: Call the plotting function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mplot_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loss' is not defined"
          ]
        }
      ],
      "source": [
        "def plot_metrics(train_loss, test_loss, train_acc, test_acc):\n",
        "    epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_loss, 'b', label='Train Loss')\n",
        "    plt.plot(epochs, test_loss, 'r', label='Test Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_acc, 'b', label='Train Accuracy')\n",
        "    plt.plot(epochs, test_acc, 'r', label='Test Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Cell 11: Call the plotting function\n",
        "plot_metrics(train_loss, test_loss, train_acc, test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5utms33YTOC",
        "outputId": "2ec5374f-4d60-4cb0-e2f3-c756c4f48e83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/20], Train Acc: 96.58%, Val Loss: 0.7156, Val Acc: 82.90%\n",
            "Epoch [12/20], Train Acc: 96.93%, Val Loss: 0.6305, Val Acc: 84.06%\n",
            "Epoch [13/20], Train Acc: 97.02%, Val Loss: 0.7211, Val Acc: 82.32%\n",
            "Epoch [14/20], Train Acc: 97.09%, Val Loss: 0.7753, Val Acc: 80.04%\n",
            "Epoch [15/20], Train Acc: 97.32%, Val Loss: 0.8426, Val Acc: 82.07%\n",
            "Epoch [16/20], Train Acc: 98.22%, Val Loss: 0.5235, Val Acc: 86.00%\n",
            "Early stopping triggered at epoch 16 with validation accuracy: 86.00%\n"
          ]
        }
      ],
      "source": [
        "def continue_training_with_early_stopping(model, criterion, optimizer, train_loader, test_loader, start_epoch, num_more_epochs, early_stop_acc=85):\n",
        "    best_acc = 0.0  # To track the best validation accuracy\n",
        "    for epoch in range(start_epoch, start_epoch + num_more_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{start_epoch + num_more_epochs}], '\n",
        "              f'Train Acc: {100 * correct / total:.2f}%, '\n",
        "              f'Val Loss: {val_loss/len(test_loader):.4f}, '\n",
        "              f'Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "        # Early stopping if validation accuracy reaches or exceeds the threshold (85%)\n",
        "        if val_acc >= early_stop_acc:\n",
        "            print(f'Early stopping triggered at epoch {epoch+1} with validation accuracy: {val_acc:.2f}%')\n",
        "            break\n",
        "\n",
        "# Continue training with early stopping\n",
        "start_epoch = 10  # Continue from the 6th epoch\n",
        "num_more_epochs = 10  # Number of additional epochs to train\n",
        "continue_training_with_early_stopping(model, criterion, optimizer, train_loader, test_loader, start_epoch, num_more_epochs, early_stop_acc=85)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m1Kyw2ZZlEb",
        "outputId": "3a8ca6ab-5fac-457b-8065-33d553055da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as 'food_classification_model.pth'\n"
          ]
        }
      ],
      "source": [
        "# Cell 13: Save the trained model\n",
        "torch.save(model.state_dict(), 'food_classification_model.pth')\n",
        "print(\"Model saved as 'food_classification_model.pth'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kbb7ikp0gjEa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "# Define the path to the dataset\n",
        "dataset_path = \"/content/drive/MyDrive/Food Classification dataset1/\"\n",
        "\n",
        "# Get class names from folder names\n",
        "class_names = sorted(os.listdir(dataset_path))\n",
        "\n",
        "# Create a dictionary mapping class indices to class names\n",
        "class_mapping = {idx: class_name for idx, class_name in enumerate(class_names)}\n",
        "\n",
        "# Save the class mapping as a pickle file\n",
        "with open('class_mapping.pkl', 'wb') as f:\n",
        "    pickle.dump(class_mapping, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq-j-ZnxiNl3",
        "outputId": "2d6ad548-ef24-4dfd-9ff0-ae97c25d535b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'Donut',\n",
              " 1: 'Hot Dog',\n",
              " 2: 'apple_pie',\n",
              " 3: 'burger',\n",
              " 4: 'butter_naan',\n",
              " 5: 'chai',\n",
              " 6: 'chapati',\n",
              " 7: 'cheesecake',\n",
              " 8: 'chicken_curry',\n",
              " 9: 'chole_bhature',\n",
              " 10: 'dal_makhani',\n",
              " 11: 'dhokla',\n",
              " 12: 'fried_rice',\n",
              " 13: 'ice_cream',\n",
              " 14: 'idli',\n",
              " 15: 'jalebi',\n",
              " 16: 'kaathi_rolls',\n",
              " 17: 'kadai_paneer',\n",
              " 18: 'kulfi',\n",
              " 19: 'masala_dosa',\n",
              " 20: 'momos',\n",
              " 21: 'omelette',\n",
              " 22: 'paani_puri',\n",
              " 23: 'pakode',\n",
              " 24: 'pav_bhaji',\n",
              " 25: 'pizza',\n",
              " 26: 'samosa',\n",
              " 27: 'sushi'}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_mapping"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}